quality_review:
  description: >
    Perform quality review of validation outputs at gate checkpoints:

    Phase: {phase}
    State: {state}
    Evidence: {evidence}

    Review for:
    1. Completeness - All required outputs present
    2. Accuracy - Calculations and analysis correct
    3. Consistency - No contradictions between sections
    4. Evidence quality - Sufficient data to support conclusions
    5. Actionability - Recommendations are specific and executable
  expected_output: >
    QA report containing:
    - status: PASSED/FAILED/NEEDS_REVISION
    - completeness_score: float 0-1
    - issues_found: list of {severity, description, location}
    - recommendations: list of improvements
    - gate_decision: proceed/revise/escalate
  agent: qa_auditor

final_audit:
  description: >
    Perform comprehensive final audit of complete validation:

    Full State: {full_state}

    Audit all aspects:
    1. Process compliance - Did we follow the methodology?
    2. Evidence chain - Is every conclusion supported?
    3. Pivot rationale - Were pivots evidence-driven?
    4. Output quality - Are deliverables complete and accurate?
    5. Learning capture - Have insights been documented?
  expected_output: >
    Final audit report containing:
    - status: PASSED/FAILED
    - overall_score: float 0-1
    - process_compliance: assessment
    - evidence_quality: assessment
    - key_findings: list
    - improvement_areas: list for future validations
  agent: qa_auditor

track_progress:
  description: >
    Track validation progress and maintain audit trail:

    Validation ID: {validation_id}
    Current Phase: {current_phase}
    Events: {events}

    Record:
    1. Phase transitions with timestamps
    2. Key decisions and rationale
    3. Evidence collected
    4. Pivots executed
    5. Human approvals obtained
  expected_output: >
    Progress report containing:
    - timeline: list of events with timestamps
    - phase_history: phases visited
    - decisions_log: key decisions made
    - evidence_summary: what was collected
    - audit_trail: complete record for compliance
  agent: accountability_tracker

capture_learnings:
  description: >
    Extract and document learnings for the Flywheel system:

    Validation Results: {results}
    Pivot History: {pivot_history}
    Evidence: {evidence}

    Identify:
    1. What worked well
    2. What didn't work
    3. Patterns to recognize
    4. Process improvements
    5. Knowledge to preserve
  expected_output: >
    Learning capture containing:
    - key_learnings: list of insights
    - pattern_matches: similar past validations
    - process_improvements: suggestions
    - knowledge_artifacts: reusable content
    - flywheel_updates: what to add to knowledge base
  agent: accountability_tracker

review_creatives:
  description: >
    Review creative artifacts (landing pages, ad creatives) before deployment:

    Artifacts: {artifacts}
    Business Context: {business_context}
    Campaign Goals: {campaign_goals}

    Using the guardian_review tool, check each artifact for:
    1. Compliance issues (misleading claims, missing disclaimers)
    2. Accessibility (alt text, contrast, screen reader compatibility)
    3. Conversion best practices (CTA clarity, value prop visibility)
    4. Security concerns (unsafe URLs, suspicious scripts)
    5. Brand consistency (tone, messaging alignment)

    Determine which artifacts can be auto-approved and which need human review.
  expected_output: >
    Creative review report containing:
    - review_results: list of {artifact_id, decision, issues}
    - auto_approved: list of artifact IDs safe to deploy
    - needs_human_review: list requiring human approval with reasons
    - rejected: list that must be fixed before any approval
    - summary: overall assessment and recommendations
  agent: qa_auditor

validate_methodology:
  description: >
    Validate strategic artifacts against Strategyzer methodology:

    Methodology Type: {methodology_type}
    Artifact: {artifact}
    Related Context: {context}

    Using the methodology_check tool, validate:
    1. VPC - Customer Profile completeness (jobs, pains, gains)
    2. VPC - Value Map completeness (products, pain relievers, gain creators)
    3. VPC - Fit between customer profile and value map
    4. BMC - All 9 building blocks present and consistent
    5. Assumptions - Properly mapped and prioritized

    Flag any structural issues that would prevent meaningful validation.
  expected_output: >
    Methodology validation report containing:
    - is_valid: boolean indicating structural soundness
    - completeness_score: 0.0-1.0 score
    - quality_score: 0.0-1.0 score
    - issues: list of {severity, component, message, suggestion}
    - ready_for_next_phase: boolean
    - summary: human-readable assessment
  agent: compliance_monitor
